model_list:
  - model_name: qwen/qwen3-coder-30b
    litellm_params:
      model: openai/qwen/qwen3-coder-30b
      api_key: "not-needed"
      api_base: http://localhost:1234/v1
      context_limit: 260000  
      max_prompt_tokens: 260000
    model_info:
      id: "qwen3-coder-30b"
  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash
      api_key: os.environ/GOOGLE_API_KEY
      context_limit: 1000000  
      max_prompt_tokens: 1000000

litellm_settings:
  # max_budget: 0.001 # not used - may provide false sense of security
  # budget_duration: 1d
  num_retries: 5
  request_timeout: 7200

general_settings: 
  master_key: sk-1234 # [OPTIONAL] Use to enforce auth on proxy. See - https://docs.litellm.ai/docs/proxy/virtual_keys
  store_model_in_db: True
  proxy_budget_rescheduler_min_time: 30
  proxy_budget_rescheduler_max_time: 64
  proxy_batch_write_at: 1
  database_connection_pool_limit: 10
  # background_health_checks: true
  # use_shared_health_check: true
  # health_check_interval: 30
  database_url: "postgresql://postgres@localhost:5432/mylitellm" # [OPTIONAL] use for token-based auth to proxy
